{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Real-Time Inferencing Service\n",
        "Now it's time to deploy a model as a real-time service that clients can use to get predictions from new data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lenovo Engineer kaustav biswas: 9831059668"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Connect to Your Workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Train and Register a Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.core import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace = ws, name = \"diabetes-training\")\n",
        "run = experiment.start_logging()\n",
        "print(\"Starting experiment:\", experiment.name)\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = pd.read_csv('../mslearn-aml-labs/data/diabetes.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a decision tree model\n",
        "print('Training a decision tree model')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the trained model\n",
        "model_file = 'diabetes_model.pkl'\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
        "\n",
        "# Complete the run\n",
        "run.complete()\n",
        "\n",
        "# Register the model\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'Inline Training'},\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "print('Model trained and registered.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Deploy a Model as a Web Service\n",
        "This model could be used in a production environment such as a doctor's surgery where only patients deemed to be at risk need to be subjected to a clinical test for diabetes. To support this scenario, you will deploy the model as a web service.\n",
        "\n",
        "#### 3.1 Pick a model from a list of models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = ws.models['diabetes_model']\n",
        "print(model.name, 'version', model.version)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 Create a folder for those."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_name = 'diabetes_service'\n",
        "\n",
        "#create a folder for the web service files\n",
        "experiment_folder = './' + folder_name\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "print(folder_name, 'folder created')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3 Create entry script\r\n",
        "The web service where we deploy the model will need some Python code to   \r\n",
        "    1.  load the input data,   \r\n",
        "    2.  get the model from the workspace,   \r\n",
        "    3.  and generate and return predictions."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $folder_name/score_diabetes.py\r\n",
        "import joblib\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "#called when the service is loaded\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    #Get the path to the depoyed model and load it\r\n",
        "    model_path = Model.get_model_path('diabetes_model')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "\r\n",
        "#called when a request is received\r\n",
        "def run(raw_data):\r\n",
        "    #Get the input data as a numpy array\r\n",
        "    data = np.array(json.loads(raw_data)['data'])\r\n",
        "    #Get a prediction from the model\r\n",
        "    predictions = model.predict(data)\r\n",
        "    #Get the corresponding classname for each of the prediction\r\n",
        "    classnames = ['non-diabetic', 'diabetic']\r\n",
        "    predicted_classes = []\r\n",
        "\r\n",
        "    for prediction in predictions:\r\n",
        "        predicted_classes.append(classnames[prediction])\r\n",
        "    \r\n",
        "    return json.dumps(predicted_classes)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Create yml file to resolve container dependency\r\n",
        "\r\n",
        "The web service will be **hosted in a container**, and the container will need to install any required Python dependencies when it gets initialized. \r\n",
        "In this case, our scoring code requires scikit-learn,"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "#Add the dependency\r\n",
        "myenv = CondaDependencies()\r\n",
        "myenv.add_conda_package(\"scikit-learn\")\r\n",
        "\r\n",
        "# Save the environment config as a .yml file\r\n",
        "env_file = folder_name + \"/diabetes_env.yml\"\r\n",
        "with open(env_file, \"w\") as f:\r\n",
        "    f.write(myenv.serialize_to_string())\r\n",
        "print('saved dependency info in', env_file)\r\n",
        "\r\n",
        "\r\n",
        "#print the .yml file\r\n",
        "with open(env_file, \"r\") as f:\r\n",
        "    print(f.read())\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Deployment steps\r\n",
        "We'll deploy the container a service named diabetes-service using  **Azure Container Instance (ACI)** . \r\n",
        "The deployment process includes the following steps:  \r\n",
        "\r\n",
        "1. Define an inference configuration  \r\n",
        "\r\n",
        "2. Define a deployment configuration   \r\n",
        "\r\n",
        "3. Deploy the model as a web service.  \r\n",
        "\r\n",
        "4. Verify the status of the deployed service.  \r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "# Configure the scoring environment\r\n",
        "inference_config = InferenceConfig(runtime= \"python\",\r\n",
        "                                   source_directory = folder_name,\r\n",
        "                                   entry_script=\"score_diabetes.py\",\r\n",
        "                                   conda_file=\"diabetes_env.yml\")\r\n",
        "\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\r\n",
        "\r\n",
        "service_name = \"diabetes-service\"\r\n",
        "\r\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\r\n",
        "\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.state)\r\n",
        "\r\n",
        "for webservice_name in ws.webservices:\r\n",
        "    print(webservice_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy model with Azure Kubernetes Service (AKS) cluster\r\n",
        " If we are deploying to an AKS cluster, we must create the cluster and a compute target for it before deploying:\r\n",
        "\r\n",
        " The code to configure an ACI deployment is similar, except that we do not need to \r\n",
        " explicitly create an ACI compute target, and we must use the deploy_configuration class from the **azureml.core.webservice.AciWebservice** namespace.  \r\n",
        " Similarly, we can use the **azureml.core.webservice.LocalWebservice** namespace to \r\n",
        " configure a local Docker-based service."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from azureml.core.compute import ComputeTarget, AksCompute\r\n",
        "\r\n",
        "#cluster_name = 'aks-cluster'\r\n",
        "#compute_config = AksCompute.provisioning_configuration(location='eastus')\r\n",
        "#production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "#production_cluster.wait_for_completion(show_output=True)\r\n",
        "\r\n",
        "\r\n",
        "#from azureml.core.webservice import AksWebservice\r\n",
        "\r\n",
        "#classifier_deploy_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Consuming a real-time inferencing service\r\n",
        "#### 4.1 For **testing**, we can use the **Azure Machine Learning SDK** \r\n",
        "to call a web service through the run method of a WebService object that references the deployed service. \r\n",
        "Typically, we send data to the run method in JSON format with the following structure:\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\r\n",
        "print ('Patient: {}'.format(x_new[0]))\r\n",
        "\r\n",
        "# Convert the array to a serializable list in a JSON document\r\n",
        "input_json = json.dumps({\"data\": x_new})\r\n",
        "\r\n",
        "# Call the web service, passing the input data (the web service will also accept the data in binary format)\r\n",
        "predictions = service.run(input_data = input_json)\r\n",
        "\r\n",
        "# Get the predicted class - it'll be the first (and only) one.\r\n",
        "predicted_classes = json.loads(predictions)\r\n",
        "print(predicted_classes[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2 In production\r\n",
        "Most client applications will not include the Azure Machine Learning SDK, \r\n",
        "and will **consume the service** through its **REST** interface. \r\n",
        "We can determine the endpoint of a deployed service in Azure machine Learning studio, \r\n",
        "or by retrieving the **scoring_uri** property of the **Webservice** object in the SDK, like this:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = service.scoring_uri\r\n",
        "print(endpoint)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we know the endpoint URI, an application can simply make an HTTP request, \r\n",
        "sending the patient data in JSON (or binary) format, and receive back the predicted class(es)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\r\n",
        "import json\r\n",
        "\r\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\r\n",
        "         [0,148,58,11,179,39.19207553,0.160829008,45]]\r\n",
        "\r\n",
        "# Convert the array to a serializable list in a JSON document\r\n",
        "input_json = json.dumps({\"data\": x_new})\r\n",
        "\r\n",
        "# Set the content type\r\n",
        "headers = { 'Content-Type':'application/json' }\r\n",
        "\r\n",
        "predictions = requests.post(endpoint, input_json, headers = headers)\r\n",
        "predicted_classes = json.loads(predictions.json())\r\n",
        "\r\n",
        "for i in range(len(x_new)):\r\n",
        "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}