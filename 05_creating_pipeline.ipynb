{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:image.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Connect to Your Workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code ACMWGQDXU to authenticate.\n",
            "Interactive authentication successfully completed.\n",
            "Ready to use Azure ML 1.6.0 to work with dp101-workspace\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Prepare the Training Data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    default_ds.upload_files(files=['../mslearn-aml-labs/data/diabetes.csv', '../mslearn-aml-labs/data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
        "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
        "                        overwrite=True, # Replace existing files of the same name\n",
        "                        show_progress=True)\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already registered.\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create Scripts\n",
        "script includes a parameter named **output_folder**, which references the folder where the trained model should be saved."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Create a folder for the pipeline step files\n",
        "experiment_folder = 'diabetes_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diabetes_pipeline\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/train_diabetes.py\n",
        "# Import libraries\n",
        "from azureml.core import Run\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier #DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--output_folder', type=str, dest='output_folder', default=\"diabetes_model\", help='output folder')\n",
        "args = parser.parse_args()\n",
        "output_folder = args.output_folder\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes data (passed as an input dataset)\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['diabetes_train'].to_pandas_dataframe()\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a decision tree model\n",
        "print('Training a decision tree model')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the trained model\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "output_path = output_folder + \"/model.pkl\"\n",
        "joblib.dump(value=model, filename=output_path)\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting diabetes_pipeline/train_diabetes.py\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Load scripts\n",
        "Pipeline will load the model from where it was saved, and then register it in the workspace. \n",
        "\n",
        "It includes a single **model_folder** parameter that contains the path to the folder where the model was saved by the previous step."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/register_diabetes.py\n",
        "# Import libraries\n",
        "import argparse\n",
        "import joblib\n",
        "from azureml.core import Workspace, Model, Run\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"diabetes_model\", help='model location')\n",
        "args = parser.parse_args()\n",
        "model_folder = args.model_folder\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "#Load the model\n",
        "print(\"Loading Model from\" + model_folder)\n",
        "model_file = model_folder + \"/model.pkl\"\n",
        "model = joblib.load(model_file)\n",
        "\n",
        "Model.register(workspace = run.experiment.workspace,\n",
        "              model_path = model_file,\n",
        "              model_name = 'diabetes_model',\n",
        "              tags = {'Training Context' : 'Pipeline'})\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting diabetes_pipeline/register_diabetes.py\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Prepare a Compute Environment for the Pipeline Steps\n",
        "\n",
        "The pipeline will eventually be published and run on-demand, so it needs a compute environment in which to run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"aml-cluster\"\n",
        "\n",
        "# Verify that cluster exists\n",
        "try:\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If not, create it\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
        "                                                           max_nodes=4,\n",
        "                                                           idle_seconds_before_scaledown=1800)\n",
        "    pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "pipeline_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The compute will require a Python environment with the necessary package dependencies installed, so we'll create a run configuration."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "diabetes_env = Environment(\"diabetes-pipeline-env\")\n",
        "diabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
        "diabetes_env.docker.enabled = True # Use a docker container\n",
        "\n",
        "# Create a set of package dependencies\n",
        "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','pandas'],\n",
        "                                             pip_packages=['azureml-sdk'])\n",
        "\n",
        "# Add the dependencies to the environment\n",
        "diabetes_env.python.conda_dependencies = diabetes_packages\n",
        "\n",
        "# Register the environment (just in case you want to use it again)\n",
        "diabetes_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'diabetes-pipeline-env')\n",
        "\n",
        "# Create a new runconfig object for the pipeline\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# Use the compute you created above. \n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# Assign the environment to the run configuration\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run configuration created.\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Create and Run pipeline\n",
        "\n",
        "Steps for the pipeline\n",
        "\n",
        "1. Write the model to a folder that can be read from by the second step\n",
        "2. The **PipelineData** object is a special kind of data reference that is used to pass data from the output of one pipeline step to the input of another, creating a dependency between them.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData\n",
        "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
        "from azureml.train.estimator import Estimator\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create a PipelineData (temporary Data Reference) for the model folder\n",
        "model_folder = PipelineData(\"model_folder\", datastore=ws.get_default_datastore())\n",
        "\n",
        "estimator = Estimator(source_directory = experiment_folder, #diabetes_pipeline\n",
        "                     compute_target = pipeline_cluster,\n",
        "                     environment_definition = pipeline_run_config.environment,\n",
        "                     entry_script = 'train_diabetes.py')\n",
        "\n",
        "# Step 1, run the estimator to train the model\n",
        "train_step = EstimatorStep(name = 'Train Model',\n",
        "                           estimator = estimator,\n",
        "                           estimator_entry_script_arguments = ['--output_folder', model_folder],\n",
        "                           inputs= [diabetes_ds.as_named_input('diabetes_train')],\n",
        "                           outputs= [model_folder],\n",
        "                           compute_target = pipeline_cluster,\n",
        "                           allow_reuse = True)\n",
        "\n",
        "\n",
        "# Step 2, run the model registration script\n",
        "register_step = PythonScriptStep(name = 'Register Model',\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"register_diabetes.py\",\n",
        "                                arguments = ['--model_folder', model_folder],\n",
        "                                inputs = [model_folder],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "print(\"Pipeline steps defined\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline steps defined\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Run pipeline as an experiment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "#Construct the pipeline\n",
        "pipeline_steps = [train_step, register_step]\n",
        "pipeline = Pipeline(workspace = ws, steps = pipeline_steps)\n",
        "print(\"pipeline is built\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace = ws, name = 'diabetes-training-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline is built\n",
            "Created step Train Model [12cdce7b][4ca0401e-e8b3-4df5-b522-f535bb3046e1], (This step will run and generate new outputs)\n",
            "Created step Register Model [7a9d941f][62ed8b16-28c7-4c26-90a2-3f9195716cbc], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun c87c4bf3-92fe-42be-8975-216b9ef950b0\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/c87c4bf3-92fe-42be-8975-216b9ef950b0?wsid=/subscriptions/661de708-75b1-41ed-806d-85f9bef3c27d/resourcegroups/dp101-resources/workspaces/dp101-workspace\n",
            "Pipeline submitted for execution.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d02c00477e0647bd875111310c6d9716",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": [
              "{\"loading\": true}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: c87c4bf3-92fe-42be-8975-216b9ef950b0\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/c87c4bf3-92fe-42be-8975-216b9ef950b0?wsid=/subscriptions/661de708-75b1-41ed-806d-85f9bef3c27d/resourcegroups/dp101-resources/workspaces/dp101-workspace\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: e86ba504-a2b8-4e05-8add-4fee0d025d60\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/e86ba504-a2b8-4e05-8add-4fee0d025d60?wsid=/subscriptions/661de708-75b1-41ed-806d-85f9bef3c27d/resourcegroups/dp101-resources/workspaces/dp101-workspace\n",
            "StepRun( Train Model ) Status: NotStarted\n",
            "StepRun( Train Model ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt\n",
            "========================================================================================================================\n",
            "2020-06-07T15:29:27Z Starting output-watcher...\n",
            "2020-06-07T15:29:27Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "4d8355064413fc71256d212d4eef2c46c5cc474fd16fb8abd52e4a6ed6831261\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt\n",
            "===============================================================================================================\n",
            "Entering job preparation. Current time:2020-06-07T15:32:04.618486\n",
            "Starting job preparation. Current time:2020-06-07T15:32:05.754536\n",
            "Extracting the control code.\n",
            "fetching and extracting the control code on master node.\n",
            "Retrieving project from snapshot: efb4be35-baa3-4c0a-96fe-4c11be8ec6d3\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 50\n",
            "Starting project file download.\n",
            "Finished project file download.\n",
            "downloadDataStore - Download from datastores if requested.\n",
            "Entering context manager injector. Current time:2020-06-07T15:32:08.843965\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "2020/06/07 15:32:12 Starting App Insight Logger for task:  runTaskLet\n",
            "Entering context manager injector. Current time:2020-06-07T15:32:15.583464\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 109\n",
            "Entering Run History Context Manager.\n",
            "Preparing to call script [ train_diabetes.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/dp101-workspace/azureml/e86ba504-a2b8-4e05-8add-4fee0d025d60/mounts/workspaceblobstore/azureml/e86ba504-a2b8-4e05-8add-4fee0d025d60/model_folder']\n",
            "After variable expansion, calling script [ train_diabetes.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/dp101-workspace/azureml/e86ba504-a2b8-4e05-8add-4fee0d025d60/mounts/workspaceblobstore/azureml/e86ba504-a2b8-4e05-8add-4fee0d025d60/model_folder']\n",
            "\n",
            "Loading Data...\n",
            "/azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py:722: UserWarning: Your pandas and pyarrow versions are incompatible. Please install pyarrow>=0.12.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install pyarrow>=0.12.0 --upgrade\n",
            "  warnings.warn('Your pandas and pyarrow versions are incompatible. '\n",
            "Training a decision tree model\n",
            "Accuracy: 0.8968888888888888\n",
            "AUC: 0.8817661637177812\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt\n",
            "===============================================================================================================\n",
            "Entering job release. Current time:2020-06-07T15:32:52.586788\n",
            "Starting job release. Current time:2020-06-07T15:32:55.285679\n",
            "Logging experiment finalizing status in history service.\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 327\n",
            "Entering context manager injector. Current time:2020-06-07T15:32:55.307264\n",
            "Job release is complete. Current time:2020-06-07T15:32:59.682870\n",
            "\n",
            "StepRun(Train Model) Execution Summary\n",
            "=======================================\n",
            "StepRun( Train Model ) Status: Finished\n",
            "{'runId': 'e86ba504-a2b8-4e05-8add-4fee0d025d60', 'target': 'aml-cluster', 'status': 'Completed', 'startTimeUtc': '2020-06-07T15:29:23.044386Z', 'endTimeUtc': '2020-06-07T15:33:15.945473Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'efb4be35-baa3-4c0a-96fe-4c11be8ec6d3', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '4ca0401e-e8b3-4df5-b522-f535bb3046e1', 'azureml.pipelinerunid': 'c87c4bf3-92fe-42be-8975-216b9ef950b0', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'ae25d68c-195b-4ea3-8d8b-5b241788448b'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_train', 'mechanism': 'Direct'}}], 'runDefinition': {'script': 'train_diabetes.py', 'useAbsolutePath': False, 'arguments': ['--output_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/e86ba504-a2b8-4e05-8add-4fee0d025d60/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'diabetes_train': {'dataLocation': {'dataset': {'id': 'ae25d68c-195b-4ea3-8d8b-5b241788448b'}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'diabetes_train', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment diabetes-training-pipeline Environment', 'version': 'Autosave_2020-06-04T15:41:22Z_2b5031cf', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk~=1.6.0']}, 'scikit-learn', 'pandas'], 'name': 'azureml_7b128fbfa600b67b9d3fa44f93754ed3'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/azureml-logs/55_azureml-execution-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt?sv=2019-02-02&sr=b&sig=ETOiivkk7V0XJ06tFPkxRV3CGWxjFypgYgRUGCzuO6g%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'azureml-logs/65_job_prep-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/azureml-logs/65_job_prep-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt?sv=2019-02-02&sr=b&sig=AURQ74ZUfGSVz27vpN%2BQONOgZ%2F%2BjoGZPGz90h0D9744%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=f0bB0O3rXYuG1iuPFGmEsIuNApreFVjO%2F7KYxgeuXrI%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'azureml-logs/75_job_post-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/azureml-logs/75_job_post-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt?sv=2019-02-02&sr=b&sig=Llg1cBSEFxQuFZq2dzwMkoysgEG5PMmwUo5k7iyQp0E%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'azureml-logs/process_info.json': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=1DVfvDFU6NuRnf6djzEaZvGKELBoDvHlzfXeH0A8Llk%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'azureml-logs/process_status.json': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=hMdwIpFfid7x0vatCHVxbTiJtI%2FPr5%2BlJwkyWKtsp4w%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'logs/azureml/109_azureml.log': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/logs/azureml/109_azureml.log?sv=2019-02-02&sr=b&sig=CNt9CbQthgQghDsK0wPmEH2D17WcxoLkaBc4i4aFQi8%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=zMFyOnDAaYggi2UESGmzt1CnX9PWplDEu%2FzS%2FMX0Szg%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=aO1Rqmrl5B5FkjUOFcct98BbBOlyW%2Bcc4tVGfjCS7T4%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=YlE9f%2BSNchPBgWrIEdttz%2Fc64FUlzeXmQWf73TC9nSA%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=dPlMQeX5IJFelpvVkYSFCVyQlmWYqzWrt9Ah%2Fmp7HhI%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.e86ba504-a2b8-4e05-8add-4fee0d025d60/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=kiAPoDeW%2BuBA78iLefzIt3s9YHvAqeJ92eyHEWqF%2BP4%3D&st=2020-06-07T15%3A23%3A42Z&se=2020-06-07T23%3A33%3A42Z&sp=r'}}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "StepRunId: 66326159-849b-48a9-9cfd-c793b5ba36af\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/66326159-849b-48a9-9cfd-c793b5ba36af?wsid=/subscriptions/661de708-75b1-41ed-806d-85f9bef3c27d/resourcegroups/dp101-resources/workspaces/dp101-workspace\n",
            "StepRun( Register Model ) Status: NotStarted\n",
            "StepRun( Register Model ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt\n",
            "========================================================================================================================\n",
            "2020-06-07T15:34:06Z Starting output-watcher...\n",
            "2020-06-07T15:34:06Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "d69c9a251aaa0da9b02d76de4c6845e12c6b20bf792b8869c8d5c4f5dc10f055\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt\n",
            "===============================================================================================================\n",
            "Entering job preparation. Current time:2020-06-07T15:34:10.244126\n",
            "Starting job preparation. Current time:2020-06-07T15:34:11.601674\n",
            "Extracting the control code.\n",
            "fetching and extracting the control code on master node.\n",
            "Retrieving project from snapshot: efb4be35-baa3-4c0a-96fe-4c11be8ec6d3\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 51\n",
            "Starting project file download.\n",
            "Finished project file download.\n",
            "downloadDataStore - Download from datastores if requested.\n",
            "Entering context manager injector. Current time:2020-06-07T15:34:14.710626\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "2020/06/07 15:34:18 Starting App Insight Logger for task:  runTaskLet\n",
            "Entering context manager injector. Current time:2020-06-07T15:34:20.434983\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 110\n",
            "Entering Run History Context Manager.\n",
            "Preparing to call script [ register_diabetes.py ] with arguments: ['--model_folder', '/mnt/batch/tasks/shared/LS_root/jobs/dp101-workspace/azureml/66326159-849b-48a9-9cfd-c793b5ba36af/mounts/workspaceblobstore/azureml/e86ba504-a2b8-4e05-8add-4fee0d025d60/model_folder']\n",
            "After variable expansion, calling script [ register_diabetes.py ] with arguments: ['--model_folder', '/mnt/batch/tasks/shared/LS_root/jobs/dp101-workspace/azureml/66326159-849b-48a9-9cfd-c793b5ba36af/mounts/workspaceblobstore/azureml/e86ba504-a2b8-4e05-8add-4fee0d025d60/model_folder']\n",
            "\n",
            "Loading Model from/mnt/batch/tasks/shared/LS_root/jobs/dp101-workspace/azureml/66326159-849b-48a9-9cfd-c793b5ba36af/mounts/workspaceblobstore/azureml/e86ba504-a2b8-4e05-8add-4fee0d025d60/model_folder\n",
            "Registering model diabetes_model\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt\n",
            "===============================================================================================================\n",
            "Entering job release. Current time:2020-06-07T15:34:30.370054\n",
            "Starting job release. Current time:2020-06-07T15:34:32.540093\n",
            "Logging experiment finalizing status in history service.\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 151\n",
            "Entering context manager injector. Current time:2020-06-07T15:34:32.562956\n",
            "Job release is complete. Current time:2020-06-07T15:34:34.262260\n",
            "\n",
            "StepRun(Register Model) Execution Summary\n",
            "==========================================\n",
            "StepRun( Register Model ) Status: Finished\n",
            "{'runId': '66326159-849b-48a9-9cfd-c793b5ba36af', 'target': 'aml-cluster', 'status': 'Completed', 'startTimeUtc': '2020-06-07T15:34:07.708531Z', 'endTimeUtc': '2020-06-07T15:34:38.074759Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'efb4be35-baa3-4c0a-96fe-4c11be8ec6d3', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '62ed8b16-28c7-4c26-90a2-3f9195716cbc', 'azureml.pipelinerunid': 'c87c4bf3-92fe-42be-8975-216b9ef950b0', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'register_diabetes.py', 'useAbsolutePath': False, 'arguments': ['--model_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/e86ba504-a2b8-4e05-8add-4fee0d025d60/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment diabetes-training-pipeline Environment', 'version': 'Autosave_2020-06-04T15:41:22Z_2b5031cf', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk~=1.6.0']}, 'scikit-learn', 'pandas'], 'name': 'azureml_7b128fbfa600b67b9d3fa44f93754ed3'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/azureml-logs/55_azureml-execution-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt?sv=2019-02-02&sr=b&sig=n8ZkDp5shJv2NpkOzq4G6IejGW7eI7T70BDSr0k2bFE%3D&st=2020-06-07T15%3A24%3A43Z&se=2020-06-07T23%3A34%3A43Z&sp=r', 'azureml-logs/65_job_prep-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/azureml-logs/65_job_prep-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt?sv=2019-02-02&sr=b&sig=qKQVw4Z1CuA0Y8UJntpZrJqc4VdlSAC6%2FImxmfDsFF8%3D&st=2020-06-07T15%3A24%3A43Z&se=2020-06-07T23%3A34%3A43Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=gWBN77blY3XxiSk6COKsrdNmQCLKBu%2FTYLMERA6vxII%3D&st=2020-06-07T15%3A24%3A44Z&se=2020-06-07T23%3A34%3A44Z&sp=r', 'azureml-logs/75_job_post-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/azureml-logs/75_job_post-tvmps_93c1681e087e8631ff5bdb15f44e64999088428d2aad04f77bb993e77c803274_d.txt?sv=2019-02-02&sr=b&sig=6pZsFTlkLRcvXSl3bra040%2FS49o%2FNwRmvEZwf9dMH4k%3D&st=2020-06-07T15%3A24%3A44Z&se=2020-06-07T23%3A34%3A44Z&sp=r', 'azureml-logs/process_info.json': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=L5H2T%2FKFCl6IOV0Y5Dfeug1Znn2dje0T8iGAcrms6FU%3D&st=2020-06-07T15%3A24%3A44Z&se=2020-06-07T23%3A34%3A44Z&sp=r', 'azureml-logs/process_status.json': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=xfBNjc9d4Qw4XXnxP%2Ff3ABBkbYdCFDLIYSV%2FnQB5jxU%3D&st=2020-06-07T15%3A24%3A44Z&se=2020-06-07T23%3A34%3A44Z&sp=r', 'logs/azureml/110_azureml.log': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/logs/azureml/110_azureml.log?sv=2019-02-02&sr=b&sig=snSrgw1q4r7PpoSLSPMNLFG7UBTh4RMwiKqg8y%2BGvPg%3D&st=2020-06-07T15%3A24%3A43Z&se=2020-06-07T23%3A34%3A43Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=qdwg875ya9NOsRspYpn%2BTT0N1KCqOl0lj%2FT%2Ff1lBehw%3D&st=2020-06-07T15%3A24%3A43Z&se=2020-06-07T23%3A34%3A43Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=bdOZre1zivvmFDKkCLxIOipu7rKll2VYqwumQhbQsHg%3D&st=2020-06-07T15%3A24%3A43Z&se=2020-06-07T23%3A34%3A43Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=L1KS4u4wnpwXULAEDQznbHCBYHLpnxyklnnWyiMM5vw%3D&st=2020-06-07T15%3A24%3A43Z&se=2020-06-07T23%3A34%3A43Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=o4lxBthdSm6e6X0T1dOb70jUSH66gNDG90rbiAjn4ck%3D&st=2020-06-07T15%3A24%3A44Z&se=2020-06-07T23%3A34%3A44Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.66326159-849b-48a9-9cfd-c793b5ba36af/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=7bzEnTESn3E8EDS8YZgxPrCgZBmdWSts5yGx03UiVT4%3D&st=2020-06-07T15%3A24%3A44Z&se=2020-06-07T23%3A34%3A44Z&sp=r'}}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': 'c87c4bf3-92fe-42be-8975-216b9ef950b0', 'status': 'Completed', 'startTimeUtc': '2020-06-07T15:26:01.501535Z', 'endTimeUtc': '2020-06-07T15:34:42.652478Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.c87c4bf3-92fe-42be-8975-216b9ef950b0/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=e6TbfCxvS3ccjuxeypT%2BkZKADNbo%2Btloxes0MvQsMgY%3D&st=2020-06-07T15%3A24%3A45Z&se=2020-06-07T23%3A34%3A45Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.c87c4bf3-92fe-42be-8975-216b9ef950b0/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=X6EKDMHeFIMpdeeQOFgKOgZyZmAzwCxRAxrouDtpa1E%3D&st=2020-06-07T15%3A24%3A45Z&se=2020-06-07T23%3A34%3A45Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://dp101worstoragea3d647ef0.blob.core.windows.net/azureml/ExperimentRun/dcid.c87c4bf3-92fe-42be-8975-216b9ef950b0/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=VQGgF5Br%2BcGPaBmgqrtlu1qQDZpJimeDJ5DGY82ud0g%3D&st=2020-06-07T15%3A24%3A45Z&se=2020-06-07T23%3A34%3A45Z&sp=r'}}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": [
              "'Finished'"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the pipeline has finished, a new model should be registered with a **Training context tag** indicating it was trained in a pipeline. Run the following code to verify this."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diabetes_model version: 4\n",
            "\t Training Context : Pipeline\n",
            "\n",
            "\n",
            "diabetes_model version: 3\n",
            "\t Training context : Inline Training\n",
            "\t AUC : 0.8753594706204287\n",
            "\t Accuracy : 0.8883333333333333\n",
            "\n",
            "\n",
            "diabetes_model version: 2\n",
            "\t Training context : Pipeline\n",
            "\n",
            "\n",
            "diabetes_model version: 1\n",
            "\t Training context : Estimator\n",
            "\t AUC : 0.8483377282451863\n",
            "\t Accuracy : 0.774\n",
            "\n",
            "\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Publish the Pipeline\n",
        "Now that you've created a pipeline and verified it works\n",
        "\n",
        "### 8.1. Publishing it as a REST service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline.publish(name = 'Diabetes_Training_Pipeline',\n",
        "                                     description = 'Trains Diabetes Model',\n",
        "                                     version = '1.0')\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://eastus.api.azureml.ms/pipelines/v1.0/subscriptions/661de708-75b1-41ed-806d-85f9bef3c27d/resourceGroups/dp101-resources/providers/Microsoft.MachineLearningServices/workspaces/dp101-workspace/PipelineRuns/PipelineSubmit/534b785a-3a61-4418-82b2-28cad96630b5\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2. Authenticating the request\n",
        "\n",
        "> To use the endpoint, client applications need to make a **REST call over HTTP**. \n",
        "> This **request** must be **authenticated**, so an authorization header is required. \n",
        "> A **real application** would require a **service principal** with which to be authenticated, but to test this out, we'll use the authorization header from my current connection to my Azure workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.3. Calling the REST interface\r\n",
        "\r\n",
        "To initiate a published endpoint, you make an HTTP request to its REST endpoint, passing an authorization header with a token for a service principal with permission to run the pipeline, and a JSON payload specifying the experiment name. The pipeline is run asynchronously, so the response from a successful REST call includes the run ID. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "experiment_name = 'Run-diabetes-pipeline'\n",
        "\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": experiment_name})\n",
        "run_id = response.json()[\"Id\"]\n",
        "run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": [
              "'4f4bd7d9-f205-4998-a096-4e1cd5f422ae'"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. RunDetails widget to view the experiment as it runs."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
        "RunDetails(published_pipeline_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52122cc542fc4615b6e1001506e2ae5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": [
              "{\"loading\": true}"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Use pipeline parameters\r\n",
        "We can increase the flexibility of a pipeline by defining parameters.  \r\n",
        "To define parameters for a pipeline, create a **PipelineParameter** object for each parameter, and specify each parameter in at least one step. \r\n",
        "\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.graph import PipelineParameter\r\n",
        "\r\n",
        "reg_param = PipelineParameter(name='reg_rate', default_value=0.01)\r\n",
        "\r\n",
        "...\r\n",
        "\r\n",
        "step2 = EstimatorStep(name = 'train model',\r\n",
        "                      estimator = sk_estimator,\r\n",
        "                      compute_target = 'aml-cluster',\r\n",
        "                      inputs=[prepped],\r\n",
        "                      estimator_entry_script_arguments=['--folder', prepped,\r\n",
        "                                                        '--reg', reg_param])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.post(rest_endpoint,\r\n",
        "                         headers=auth_header,\r\n",
        "                         json={\"ExperimentName\": \"run_training_pipeline\",\r\n",
        "                               \"ParameterAssignments\": {\"reg_rate\": 0.1}})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11. Scheduling a pipeline for periodic intervals\r\n",
        "\r\n",
        "To schedule a pipeline to run at periodic intervals, you must define a **ScheduleRecurrence** that determines the run frequency, and use it to create a Schedule."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import ScheduleRecurrence, Schedule\r\n",
        "\r\n",
        "daily = ScheduleRecurrence(frequency='Day', interval=1)\r\n",
        "pipeline_schedule = Schedule.create(ws, name='Daily Training',\r\n",
        "                                        description='trains model every day',\r\n",
        "                                        pipeline_id=published_pipeline.id,\r\n",
        "                                        experiment_name='Training_Pipeline',\r\n",
        "                                        recurrence=daily)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12. Triggering a pipeline run on data changes\r\n",
        "To schedule a pipeline to run whenever data changes, we must create a **Schedule** that monitors a specified path on a datastore, like this:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Datastore\r\n",
        "from azureml.pipeline.core import Schedule\r\n",
        "\r\n",
        "training_datastore = Datastore(workspace=ws, name='blob_data')\r\n",
        "pipeline_schedule = Schedule.create(ws, name='Reactive Training',\r\n",
        "                                    description='trains model on data change',\r\n",
        "                                    pipeline_id=published_pipeline_id,\r\n",
        "                                    experiment_name='Training_Pipeline',\r\n",
        "                                    datastore=training_datastore,\r\n",
        "                                    path_on_datastore='data/training')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}